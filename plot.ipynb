{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3157b393",
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "api = wandb.Api()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f81ddd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_cls_runs(loss_data, acc_data, keys, figsize=(12, 5)):\n",
        "    \"\"\"\n",
        "    Plot train/loss (left) and val/accuracy (right) for the given run keys.\n",
        "    loss_data: dict[key] -> list of train/loss values (per step)\n",
        "    acc_data: dict[key] -> list of val/accuracy values (per epoch)\n",
        "    keys: list of key names to plot\n",
        "    \"\"\"\n",
        "    fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "    for key in keys:\n",
        "        if key not in loss_data or key not in acc_data:\n",
        "            continue\n",
        "        losses = loss_data[key]\n",
        "        accs = acc_data[key]\n",
        "        # Left: train loss (x = step index)\n",
        "        ax_loss.plot(range(len(losses)), losses, label=key)\n",
        "        # Right: val accuracy (x = epoch 1, 2, ...)\n",
        "        epochs = list(range(1, len(accs) + 1))\n",
        "        ax_acc.plot(epochs, accs, \"o-\", label=key)\n",
        "        for ep, val in zip(epochs, accs):\n",
        "            ax_acc.annotate(f\"{val:.1f}\", (ep, val), textcoords=\"offset points\", xytext=(0, 6), ha=\"center\", fontsize=8)\n",
        "\n",
        "    ax_loss.set_xlabel(\"Step\")\n",
        "    ax_loss.set_ylabel(\"train/loss\")\n",
        "    ax_loss.set_title(\"Train Loss\")\n",
        "    ax_loss.legend()\n",
        "    ax_loss.grid(True, alpha=0.3)\n",
        "\n",
        "    ax_acc.set_xlabel(\"Epoch\")\n",
        "    ax_acc.set_ylabel(\"val/accuracy\")\n",
        "    ax_acc.set_title(\"Val Accuracy\")\n",
        "    ax_acc.legend()\n",
        "    ax_acc.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    return fig, (ax_loss, ax_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b95901",
      "metadata": {},
      "outputs": [],
      "source": [
        "cls_runs = {\n",
        "    \"Baseline\": \"chentianyi453/CSE256_PA2_CLS/rdol824l\",\n",
        "    \"RoPE\": \"chentianyi453/CSE256_PA2_CLS/78g1y84e\",\n",
        "    \"DisentangledAttn\": \"chentianyi453/CSE256_PA2_CLS/17qoo6hl\",\n",
        "    \"[CLS] Token\": \"chentianyi453/CSE256_PA2_CLS/xtpz3nln\"\n",
        "}\n",
        "loss_data = {exp_name: api.run(run).history()[\"train/loss\"].to_list() for exp_name, run in cls_runs.items()}\n",
        "loss_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350f0af3",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/home/tianyichen/cse256/UCSD-CSE256-2026WI-PA2/cls_val_acc.csv\")\n",
        "acc_data = dict()\n",
        "acc_data[\"Baseline\"] = data[\"Baseline - val/accuracy\"].tolist()\n",
        "acc_data[\"RoPE\"] = data[\"RoPE - val/accuracy\"].tolist()\n",
        "acc_data[\"DisentangledAttn\"] = data[\"DisentangledAttn - val/accuracy\"].tolist()\n",
        "acc_data[\"[CLS] Token\"] = data[\"[CLS] Token - val/accuracy\"].tolist()\n",
        "acc_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05044005",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LM: train loss (every step) + train perplexity (5 points at 100,200,300,400,500)\n",
        "train_ppl_df = pd.read_csv(\"/home/tianyichen/cse256/UCSD-CSE256-2026WI-PA2/train_ppl.csv\")\n",
        "steps_ppl = train_ppl_df[\"Step\"].astype(int).tolist()\n",
        "train_ppl = train_ppl_df[\"Baseline - train/perplexity\"].tolist()\n",
        "# train_loss: from wandb (500 steps)\n",
        "runs_lm = [\"chentianyi453/CSE256_PA2_LM/iubeig97\"]\n",
        "hist = api.run(runs_lm[0]).history()\n",
        "train_loss = hist[\"train/loss\"].tolist()[:500]\n",
        "\n",
        "fig, (ax_loss, ax_ppl) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax_loss.plot(range(len(train_loss)), train_loss)\n",
        "ax_loss.set_xlabel(\"Step\")\n",
        "ax_loss.set_ylabel(\"train/loss\")\n",
        "ax_loss.set_title(\"Train Loss\")\n",
        "ax_loss.grid(True, alpha=0.3)\n",
        "\n",
        "ax_ppl.plot(steps_ppl, train_ppl, \"o-\")\n",
        "for s, v in zip(steps_ppl, train_ppl):\n",
        "    ax_ppl.annotate(f\"{v:.1f}\", (s, v), textcoords=\"offset points\", xytext=(0, 8), ha=\"center\", fontsize=9)\n",
        "ax_ppl.set_xlabel(\"Step\")\n",
        "ax_ppl.set_ylabel(\"train/perplexity\")\n",
        "ax_ppl.set_title(\"Train Perplexity\")\n",
        "ax_ppl.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c9e156",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LM: three test perplexities (wbush, obama, hbush) â€” 5 points each, annotated\n",
        "base = \"/home/tianyichen/cse256/UCSD-CSE256-2026WI-PA2\"\n",
        "wbush = pd.read_csv(f\"{base}/wbush_ppl.csv\")\n",
        "obama = pd.read_csv(f\"{base}/obama_ppl.csv\")\n",
        "hbush = pd.read_csv(f\"{base}/hbush_ppl.csv\")\n",
        "\n",
        "def plot_ppl_5(ax, steps, values, title):\n",
        "    ax.plot(steps, values, \"o-\")\n",
        "    for s, v in zip(steps, values):\n",
        "        ax.annotate(f\"{v:.1f}\", (s, v), textcoords=\"offset points\", xytext=(0, 8), ha=\"center\", fontsize=9)\n",
        "    ax.set_xlabel(\"Step\")\n",
        "    ax.set_ylabel(\"Perplexity\")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 5))\n",
        "steps = wbush[\"train/iter\"].astype(int).tolist()\n",
        "plot_ppl_5(ax1, steps, wbush[\"Baseline - val/perplexity_wbush\"].tolist(), \"Val Perplexity (W. Bush)\")\n",
        "plot_ppl_5(ax2, steps, obama[\"Baseline - val/perplexity_obama\"].tolist(), \"Val Perplexity (Obama)\")\n",
        "plot_ppl_5(ax3, steps, hbush[\"Baseline - val/perplexity_hbush\"].tolist(), \"Val Perplexity (H. Bush)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22a71067",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: after loading data and loss_data, call with desired keys\n",
        "keys = [\"Baseline\", \"RoPE\"]\n",
        "# keys = [\"Baseline\", \"RoPE\", \"DisentangledAttn\", \"[CLS] Token\"]\n",
        "plot_cls_runs(loss_data, acc_data, keys)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64f095c",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
